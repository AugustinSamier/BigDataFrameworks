{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning - Certain functionality \n",
      "             requires requests_html, which is not installed.\n",
      "             \n",
      "             Install using: \n",
      "             pip install requests_html\n",
      "             \n",
      "             After installation, you may have to restart your Python session.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import yahoo_fin.stock_info as si\n",
    "from yahoo_fin.stock_info import get_data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from ipywidgets import interact, widgets,Output,VBox\n",
    "from datetime import timedelta,datetime\n",
    "from IPython.display import display\n",
    "from pyspark.sql import SparkSession,Row\n",
    "from pyspark.sql.functions import col,to_date,avg,stddev,mean,lit,count,when,corr,lag,last\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import StructType,StructField,StringType,DoubleType,TimestampType\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .appName(\"BigDataFramework\")\\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.cores\", \"2\") \\\n",
    "    .config(\"spark.python.worker.reuse\", \"true\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take APPLE as a first example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-02</td>\n",
       "      <td>66.817497</td>\n",
       "      <td>67.062500</td>\n",
       "      <td>65.862503</td>\n",
       "      <td>66.040001</td>\n",
       "      <td>64.024628</td>\n",
       "      <td>94487200</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>64.577499</td>\n",
       "      <td>64.882500</td>\n",
       "      <td>64.072502</td>\n",
       "      <td>64.862503</td>\n",
       "      <td>62.883064</td>\n",
       "      <td>114430400</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-04</td>\n",
       "      <td>65.267502</td>\n",
       "      <td>65.827499</td>\n",
       "      <td>65.169998</td>\n",
       "      <td>65.434998</td>\n",
       "      <td>63.438091</td>\n",
       "      <td>67181600</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-05</td>\n",
       "      <td>65.947502</td>\n",
       "      <td>66.472504</td>\n",
       "      <td>65.682503</td>\n",
       "      <td>66.394997</td>\n",
       "      <td>64.368782</td>\n",
       "      <td>74424400</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-06</td>\n",
       "      <td>66.870003</td>\n",
       "      <td>67.750000</td>\n",
       "      <td>66.824997</td>\n",
       "      <td>67.677498</td>\n",
       "      <td>65.612137</td>\n",
       "      <td>106075600</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>2024-11-22</td>\n",
       "      <td>228.059998</td>\n",
       "      <td>230.720001</td>\n",
       "      <td>228.059998</td>\n",
       "      <td>229.869995</td>\n",
       "      <td>229.869995</td>\n",
       "      <td>38168300</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>2024-11-25</td>\n",
       "      <td>231.460007</td>\n",
       "      <td>233.250000</td>\n",
       "      <td>229.740005</td>\n",
       "      <td>232.869995</td>\n",
       "      <td>232.869995</td>\n",
       "      <td>90152800</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>2024-11-26</td>\n",
       "      <td>233.330002</td>\n",
       "      <td>235.570007</td>\n",
       "      <td>233.330002</td>\n",
       "      <td>235.059998</td>\n",
       "      <td>235.059998</td>\n",
       "      <td>45986200</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>2024-11-27</td>\n",
       "      <td>234.470001</td>\n",
       "      <td>235.690002</td>\n",
       "      <td>233.809998</td>\n",
       "      <td>234.929993</td>\n",
       "      <td>234.929993</td>\n",
       "      <td>33498400</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>2024-11-29</td>\n",
       "      <td>234.809998</td>\n",
       "      <td>237.809998</td>\n",
       "      <td>233.970001</td>\n",
       "      <td>237.330002</td>\n",
       "      <td>237.330002</td>\n",
       "      <td>28481400</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1258 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date        open        high         low       close    adjclose  \\\n",
       "0    2019-12-02   66.817497   67.062500   65.862503   66.040001   64.024628   \n",
       "1    2019-12-03   64.577499   64.882500   64.072502   64.862503   62.883064   \n",
       "2    2019-12-04   65.267502   65.827499   65.169998   65.434998   63.438091   \n",
       "3    2019-12-05   65.947502   66.472504   65.682503   66.394997   64.368782   \n",
       "4    2019-12-06   66.870003   67.750000   66.824997   67.677498   65.612137   \n",
       "...         ...         ...         ...         ...         ...         ...   \n",
       "1253 2024-11-22  228.059998  230.720001  228.059998  229.869995  229.869995   \n",
       "1254 2024-11-25  231.460007  233.250000  229.740005  232.869995  232.869995   \n",
       "1255 2024-11-26  233.330002  235.570007  233.330002  235.059998  235.059998   \n",
       "1256 2024-11-27  234.470001  235.690002  233.809998  234.929993  234.929993   \n",
       "1257 2024-11-29  234.809998  237.809998  233.970001  237.330002  237.330002   \n",
       "\n",
       "         volume ticker  \n",
       "0      94487200   AAPL  \n",
       "1     114430400   AAPL  \n",
       "2      67181600   AAPL  \n",
       "3      74424400   AAPL  \n",
       "4     106075600   AAPL  \n",
       "...         ...    ...  \n",
       "1253   38168300   AAPL  \n",
       "1254   90152800   AAPL  \n",
       "1255   45986200   AAPL  \n",
       "1256   33498400   AAPL  \n",
       "1257   28481400   AAPL  \n",
       "\n",
       "[1258 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nas_aapl= get_data(\"aapl\",start_date=\"11/30/2019\",end_date=\"11/30/2024\",index_as_date =False,interval=\"1d\") #différents interval (1m to 3months)\n",
    "nas_aapl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1258 entries, 0 to 1257\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   date      1258 non-null   datetime64[ns]\n",
      " 1   open      1258 non-null   float64       \n",
      " 2   high      1258 non-null   float64       \n",
      " 3   low       1258 non-null   float64       \n",
      " 4   close     1258 non-null   float64       \n",
      " 5   adjclose  1258 non-null   float64       \n",
      " 6   volume    1258 non-null   int64         \n",
      " 7   ticker    1258 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(5), int64(1), object(1)\n",
      "memory usage: 78.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(nas_aapl.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we can check how much different tickers there are in the NASDAQ stock market as we want to work on this specific market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickers in Nasdaq: 4791\n",
      "['AACG', 'AADI', 'AADR', 'AAL', 'AAME', 'AAOI', 'AAON', 'AAPB', 'AAPD', 'AAPL', 'AAPU', 'AAXJ', 'ABAT', 'ABCL', 'ABCS', 'ABEO', 'ABL', 'ABLLL', 'ABLLW', 'ABLV', 'ABLVW', 'ABNB', 'ABOS', 'ABP', 'ABPWW', 'ABSI', 'ABTS', 'ABUS', 'ABVC', 'ABVE']\n"
     ]
    }
   ],
   "source": [
    "nas_list=si.tickers_nasdaq()\n",
    "print(\"Tickers in Nasdaq:\",len(nas_list))\n",
    "print(nas_list[0:30])\n",
    "nasdaq_list=nas_list[0:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We put the tickers we want in a dataframe so we can access it by the name of the ticker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABLVW is not available now : 'timestamp'\n"
     ]
    }
   ],
   "source": [
    "structDay=StructType([\n",
    "    StructField(\"date\",TimestampType(),True),\n",
    "    StructField(\"open\",DoubleType(),True),\n",
    "    StructField(\"high\",DoubleType(),True),\n",
    "    StructField(\"low\",DoubleType(),True),\n",
    "    StructField(\"close\",DoubleType(),True),\n",
    "    StructField(\"adjclose\",DoubleType(),True),\n",
    "    StructField(\"volume\",DoubleType(),True),\n",
    "    StructField(\"ticker\",StringType(),True)\n",
    "])\n",
    "\n",
    "structMin=StructType([\n",
    "    StructField(\"date\",TimestampType(),True),\n",
    "    StructField(\"open\",DoubleType(),True),\n",
    "    StructField(\"high\",DoubleType(),True),\n",
    "    StructField(\"low\",DoubleType(),True),\n",
    "    StructField(\"close\",DoubleType(),True),\n",
    "    StructField(\"volume\",DoubleType(),True),\n",
    "    StructField(\"ticker\",StringType(),True)\n",
    "])\n",
    "\n",
    "dfday=spark.createDataFrame([],structDay)\n",
    "dfmin=spark.createDataFrame([],structMin)\n",
    "dateToday=datetime.today().strftime(\"%Y-%m-%d\")\n",
    "date7days=(datetime.today()-timedelta(days=7)).strftime(\"%Y-%m-%d\")\n",
    "valid_nasdaq_list=[]\n",
    "\n",
    "for ticker in nasdaq_list:\n",
    "    try:\n",
    "        data_tickers_min=get_data(ticker,start_date=date7days,index_as_date=True,interval=\"1m\")\n",
    "        data_tickers_d= get_data(ticker,start_date=\"11/30/2014\",index_as_date=True,interval=\"1d\")\n",
    "        data_tickers_min[\"ticker\"] = data_tickers_min[\"ticker\"].astype(\"string\")\n",
    "        data_tickers_d[\"ticker\"] = data_tickers_d[\"ticker\"].astype(\"string\")\n",
    "        if((len(data_tickers_d))and(len(data_tickers_min))): #we put this treshold to remove tickers with small amount of data\n",
    "            data_tickers_min=spark.createDataFrame(data_tickers_min.reset_index())\n",
    "            data_tickers_d=spark.createDataFrame(data_tickers_d.reset_index())\n",
    "            dfmin=dfmin.union(data_tickers_min)\n",
    "            dfday=dfday.union(data_tickers_d)\n",
    "            valid_nasdaq_list.append(ticker)\n",
    "        else:\n",
    "            print(f\"{ticker} removed\")\n",
    "    except Exception as e:\n",
    "        print(f\"{ticker} is not available now : {e}\")\n",
    "def dataEng(data):\n",
    "    df=data\n",
    "    df=df.withColumn(\"date\", to_date(col(\"date\"))) #To put the right date type\n",
    "    df=df.withColumn(\"variation\",col(\"high\")-col(\"low\")) #Variation between the highest value of the day and the lowest\n",
    "    df=df.na.drop()\n",
    "    return df\n",
    "\n",
    "df_day=dataEng(dfday)\n",
    "df_min=dataEng(dfmin)\n",
    "\n",
    "windowReturn=Window.partitionBy(\"ticker\").orderBy(\"date\")\n",
    "window50=Window.partitionBy(\"ticker\").orderBy(\"date\").rowsBetween(-49,0)\n",
    "window200=Window.partitionBy(\"ticker\").orderBy(\"date\").rowsBetween(-199,0)\n",
    "df_day=df_day.withColumn(\"return\",(col(\"close\")-lag(\"close\",1).over(windowReturn))/lag(\"close\",1).over(windowReturn))\n",
    "df_day=df_day.withColumn(\"SMA50\",avg(col(\"close\")).over(window50)) #SMA (Simple Moving Average) for 50 days\n",
    "df_day=df_day.withColumn(\"SMA200\",avg(col(\"close\")).over(window200)) #for 200 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o4345.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 9) (Augustin executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:108)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 35 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)\r\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)\r\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4333)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3316)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4323)\r\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4321)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4321)\r\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:3316)\r\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:3539)\r\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:280)\r\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:315)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:108)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 35 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_day\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopen\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mlimit(\u001b[38;5;241m5\u001b[39m)\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\asami\\anaconda3\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:947\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    888\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \n\u001b[0;32m    890\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;124;03m    name | Bob\u001b[39;00m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_show_string(n, truncate, vertical))\n",
      "File \u001b[1;32mc:\\Users\\asami\\anaconda3\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:965\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m    960\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    961\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m    962\u001b[0m     )\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[1;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mshowString(n, \u001b[38;5;241m20\u001b[39m, vertical)\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\asami\\anaconda3\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\asami\\anaconda3\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mc:\\Users\\asami\\anaconda3\\Lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o4345.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 9) (Augustin executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:108)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 35 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)\r\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)\r\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4333)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3316)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4323)\r\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4321)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4321)\r\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:3316)\r\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:3539)\r\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:280)\r\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:315)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:108)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 35 more\r\n"
     ]
    }
   ],
   "source": [
    "df_day.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the sharp return ratio and explain the meaning of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpReturnDf=spark.createDataFrame(valid_nasdaq_list,\"string\").toDF(\"ticker\")\n",
    "risk_free=0.02/252 #2%/per year cause there are 252 days of open stock market per year\n",
    "\n",
    "for ticker in valid_nasdaq_list:\n",
    "    tick=yf.Ticker(ticker)\n",
    "    info=tick.info\n",
    "    \n",
    "    peRatio=info.get(\"trailingPE\")\n",
    "    betaRatio=info.get(\"beta\")\n",
    "    revenueGrowth=info.get(\"revenueGrowth\")\n",
    "    dailyVolume=info.get(\"volume\")\n",
    "    averageVolume=info.get(\"averageVolume\")\n",
    "    \n",
    "    dfreturn=df_day.filter(col(\"ticker\")==ticker)\n",
    "    returnR=dfreturn.agg(avg(\"return\")).collect()[0][0] #average of the return\n",
    "    vola=dfreturn.agg(stddev(\"return\")).collect()[0][0] #standard deviation = \"écart type\"\n",
    "\n",
    "    latestClose=dfreturn.select(last(\"close\").alias(\"latestClose\")).collect()[0][\"latestClose\"]\n",
    "    sma50=dfreturn.select(last(\"SMA50\").alias(\"latestSMA50\")).collect()[0][\"latestSMA50\"] if dfreturn.filter(col(\"SMA50\").isNotNull()).limit(1).count()==1 else None\n",
    "    #We check if there is at least a line with a non-NULL value and if so it takes the last value of it in the column\n",
    "    sma200=dfreturn.select(last(\"SMA200\").alias(\"latestSMA200\")).collect()[0][\"latestSMA200\"] if dfreturn.filter(col(\"SMA200\").isNotNull()).limit(1).count()==1 else None\n",
    "\n",
    "    sharpReturnDf=sharpReturnDf.withColumn(\"close\",when(col(\"ticker\")==lit(ticker),lit(latestClose)))\n",
    "    sharpReturnDf=sharpReturnDf.withColumn(\"SMA50\",when(col(\"ticker\")==lit(ticker),lit(sma50)))\n",
    "    sharpReturnDf=sharpReturnDf.withColumn(\"SMA200\",when(col(\"ticker\")==lit(ticker),lit(sma200)))\n",
    "    sharpReturnDf=sharpReturnDf.withColumn(\"sharpReturn\",when(col(\"ticker\")==lit(ticker),lit((returnR-risk_free)/vola)))\n",
    "    sharpReturnDf=sharpReturnDf.withColumn(\"peRatio\",when(col(\"ticker\")==lit(ticker),lit(peRatio)))\n",
    "    sharpReturnDf=sharpReturnDf.withColumn(\"betaRatio\",when(col(\"ticker\")==lit(ticker),lit(betaRatio)))\n",
    "    sharpReturnDf=sharpReturnDf.withColumn(\"vola\",when(col(\"ticker\")==lit(ticker),lit(vola)))\n",
    "    sharpReturnDf=sharpReturnDf.withColumn(\"revenueGrowth\",when(col(\"ticker\")==lit(ticker),lit(revenueGrowth)))\n",
    "    sharpReturnDf=sharpReturnDf.withColumn(\"dailyVolume\",when(col(\"ticker\")==lit(ticker),lit(dailyVolume)))\n",
    "    sharpReturnDf=sharpReturnDf.withColumn(\"averageVolume\",when(col(\"ticker\")==lit(ticker),lit(averageVolume)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>close</th>\n",
       "      <th>SMA50</th>\n",
       "      <th>SMA200</th>\n",
       "      <th>sharpReturn</th>\n",
       "      <th>peRatio</th>\n",
       "      <th>betaRatio</th>\n",
       "      <th>vola</th>\n",
       "      <th>revenueGrowth</th>\n",
       "      <th>dailyVolume</th>\n",
       "      <th>averageVolume</th>\n",
       "      <th>sharpRatioMeaning</th>\n",
       "      <th>longTermScore</th>\n",
       "      <th>shortTermScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAON</td>\n",
       "      <td>121.419998</td>\n",
       "      <td>125.96160</td>\n",
       "      <td>97.650950</td>\n",
       "      <td>0.046718</td>\n",
       "      <td>53.254387</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.021743</td>\n",
       "      <td>0.168</td>\n",
       "      <td>236399.0</td>\n",
       "      <td>421632.0</td>\n",
       "      <td>Not so bad</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AADI</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>2.29450</td>\n",
       "      <td>1.915575</td>\n",
       "      <td>-0.001865</td>\n",
       "      <td>None</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.055983</td>\n",
       "      <td>0.210</td>\n",
       "      <td>363395.0</td>\n",
       "      <td>298100.0</td>\n",
       "      <td>Bad</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AAXJ</td>\n",
       "      <td>72.989998</td>\n",
       "      <td>75.25860</td>\n",
       "      <td>72.657550</td>\n",
       "      <td>0.005234</td>\n",
       "      <td>14.801209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>224829.0</td>\n",
       "      <td>549109.0</td>\n",
       "      <td>Not so bad</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ABVC</td>\n",
       "      <td>0.581000</td>\n",
       "      <td>0.55558</td>\n",
       "      <td>0.790500</td>\n",
       "      <td>0.019933</td>\n",
       "      <td>None</td>\n",
       "      <td>0.816</td>\n",
       "      <td>82.736597</td>\n",
       "      <td>18.175</td>\n",
       "      <td>341327.0</td>\n",
       "      <td>258488.0</td>\n",
       "      <td>Not so bad</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ABL</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>8.32500</td>\n",
       "      <td>10.011080</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>None</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.026272</td>\n",
       "      <td>0.333</td>\n",
       "      <td>299167.0</td>\n",
       "      <td>184232.0</td>\n",
       "      <td>Not so bad</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticker       close      SMA50     SMA200  sharpReturn    peRatio  \\\n",
       "3    AAON  121.419998  125.96160  97.650950     0.046718  53.254387   \n",
       "0    AADI    3.210000    2.29450   1.915575    -0.001865       None   \n",
       "8    AAXJ   72.989998   75.25860  72.657550     0.005234  14.801209   \n",
       "19   ABVC    0.581000    0.55558   0.790500     0.019933       None   \n",
       "12    ABL    7.750000    8.32500  10.011080     0.001945       None   \n",
       "\n",
       "    betaRatio       vola  revenueGrowth  dailyVolume  averageVolume  \\\n",
       "3       0.791   0.021743          0.168     236399.0       421632.0   \n",
       "0       0.369   0.055983          0.210     363395.0       298100.0   \n",
       "8         NaN   0.012677            NaN     224829.0       549109.0   \n",
       "19      0.816  82.736597         18.175     341327.0       258488.0   \n",
       "12      0.148   0.026272          0.333     299167.0       184232.0   \n",
       "\n",
       "   sharpRatioMeaning  longTermScore  shortTermScore  \n",
       "3         Not so bad              6               2  \n",
       "0                Bad              6               5  \n",
       "8         Not so bad              5               0  \n",
       "19        Not so bad              4               5  \n",
       "12        Not so bad              4               4  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sharpRatioLabel(ratio):\n",
    "    if ratio<0:\n",
    "        return \"Bad\"\n",
    "    if ((ratio>0) & (ratio<1)):\n",
    "        return \"Not so bad\"\n",
    "    if ((ratio>=1) & (ratio<2)):\n",
    "        return \"Good\"\n",
    "    if (ratio >=2):\n",
    "        return \"Amazing\"\n",
    "\n",
    "def longTermScore(line):\n",
    "    score=0\n",
    "    if ((line[\"peRatio\"]!=None) and (line[\"peRatio\"]<20)): #PE ratio is how much investor pays to get a $ of benefice\n",
    "        score+=3 #PE ratio is 1.5 more important than the revenue growth and the beta ratio -> PE ratio <20 -> company under-evaluated\n",
    "    if ((line[\"revenueGrowth\"]!=None)and(line[\"revenueGrowth\"]>0.1)):\n",
    "        score+=2 #ratio of revenue growth is how much % the revenues of the company grew -> 0.1=10% \n",
    "    if ((line[\"betaRatio\"]!=None)and(line[\"betaRatio\"]<1)):\n",
    "        score+=2 #betaratio is the volability of comparated to the global market -> if < 1 then it's less volatible than the global market\n",
    "    if ((line[\"averageVolume\"]!=None)and(line[\"averageVolume\"]>1000000)):\n",
    "        score += 1 #We count the average volume of transaction as a criteria for long term investments -> meaning it's pretty active\n",
    "    if ((line[\"close\"]!=None)and(line[\"SMA50\"]!=None)and(line[\"SMA200\"]!=None)and(line[\"close\"]>line[\"SMA200\"])and(line[\"SMA50\"]>line[\"SMA200\"])):\n",
    "        #checking if the actual price is higher than the moving average on 200 days, meaning it's actually going up, and checking if the\n",
    "        #moving average on 50 days is higher than the moving average on 200 days, meaning it tends to price up\n",
    "        score+=2\n",
    "    return score\n",
    "\n",
    "def shortTermScore(line):\n",
    "    score=0\n",
    "    if ((line[\"sharpReturn\"]!=None)and(line[\"sharpReturn\"]>1)):\n",
    "        score+=3 #return adjusted to the risk -> we use it to see if the return is worth the risk ->> if it's >1 then the return is worth the risk\n",
    "    if ((line[\"betaRatio\"]!=None)and(line[\"betaRatio\"]>1)):\n",
    "        score+=2 #betaratio >1 so more volatible than the global market\n",
    "    if ((line[\"vola\"]!=None)and(line[\"vola\"]>0.02)):\n",
    "        score+=2 #high volability -> more likely to be good a short term investment -> volability is the \"écart type\" of the return (indicates if it's stable)\n",
    "    if ((line[\"dailyVolume\"]!=None)and(line[\"dailyVolume\"]>line[\"averageVolume\"])):\n",
    "        score+=2 #if there is an un-normal recent activity then it's more likely to be a good short term investment\n",
    "    if ((line[\"close\"]!=None)and(line[\"SMA50\"]!=None)and(line[\"close\"]>line[\"SMA50\"])): #latest close value > MA 50 days -> recent price up and activity\n",
    "        score+=1\n",
    "    return score\n",
    "\n",
    "sharpReturnDf[\"sharpRatioMeaning\"]=sharpReturnDf[\"sharpReturn\"].apply(sharpRatioLabel)\n",
    "sharpReturnDf[\"longTermScore\"]=sharpReturnDf.apply(longTermScore,axis=1)\n",
    "sharpReturnDf[\"shortTermScore\"]=sharpReturnDf.apply(shortTermScore,axis=1)\n",
    "\n",
    "sharpReturnDf=sharpReturnDf.sort_values(by=[\"longTermScore\",\"sharpReturn\"],ascending=[False,False])\n",
    "sharpReturnDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AADI : 652\n",
      "AAL : 1377\n",
      "AAOI : 1322\n",
      "AAON : 705\n",
      "AAPB : 246\n",
      "AAPD : 659\n",
      "AAPL : 1378\n",
      "AAPU : 788\n",
      "AAXJ : 502\n",
      "ABAT : 1378\n",
      "ABCL : 1256\n",
      "ABEO : 393\n",
      "ABL : 582\n",
      "ABLLL : 173\n",
      "ABNB : 1369\n",
      "ABOS : 1083\n",
      "ABP : 996\n",
      "ABSI : 1284\n",
      "ABUS : 872\n",
      "ABVC : 223\n"
     ]
    }
   ],
   "source": [
    "for ticker in valid_nasdaq_list:\n",
    "    counter=df_min[df_min[\"ticker\"]==ticker][\"ticker\"].count()\n",
    "    print(f\"{ticker} : {counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date         0\n",
      "open         0\n",
      "high         0\n",
      "low          0\n",
      "close        0\n",
      "volume       0\n",
      "ticker       0\n",
      "variation    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_min.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Analysis and visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interface to help you chose a company in fonction of the desired term time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106319ebda6c43bbba3abe431ff8d3f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Term Time : ', options=('Long Term', 'Short Term'), value='Long Term')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76e715d78264a9a9b459cc677ebe703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Display', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def recommandations(termTime):\n",
    "    \n",
    "    if(termTime==\"Long Term\"):\n",
    "        sortDF=sharpReturnDf.sort_values(by=[\"longTermScore\",\"sharpReturn\"],ascending=[False,False])\n",
    "        title=\"Best companies to invest in for long time term investment: \"\n",
    "        print(f\"{title}\\n\")\n",
    "        print(sortDF[[\"ticker\",\"longTermScore\"]])\n",
    "    else:\n",
    "        sortDF=sharpReturnDf.sort_values(by=[\"shortTermScore\",\"sharpReturn\"],ascending=[False,False])\n",
    "        title=\"Best companies to invest in for short time term investment: \"\n",
    "        print(f\"{title}\\n\")\n",
    "        print(sortDF[[\"ticker\",\"shortTermScore\"]])\n",
    "\n",
    "termTime=widgets.Dropdown(\n",
    "    options=[\"Long Term\",\"Short Term\"],\n",
    "    value=\"Long Term\",\n",
    "    description=\"Term Time : \"\n",
    ")\n",
    "\n",
    "def click(button):\n",
    "    recommandations(termTime.value)\n",
    "\n",
    "button=widgets.Button(description=\"Display\")\n",
    "button.on_click(click)\n",
    "display(termTime,button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interface to show the variation in stock value of a company:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4d80e657cf45a89e667b49b4868d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Select Ticker: ', options=('AADI', 'AAL', 'AAOI', 'AAON', 'AAPB', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "connectgaps": false,
         "line": {
          "color": "blue",
          "width": 2
         },
         "mode": "lines",
         "name": "Close value (AADI)",
         "type": "scatter",
         "x": [
          "27 14:30",
          "27 14:31",
          "27 14:32",
          "27 14:33",
          "27 14:40",
          "27 14:41",
          "27 14:44",
          "27 14:45",
          "27 14:46",
          "27 14:48",
          "27 14:49",
          "27 14:50",
          "27 14:51",
          "27 14:53",
          "27 14:56",
          "27 14:57",
          "27 14:58",
          "27 15:03",
          "27 15:04",
          "27 15:05",
          "27 15:06",
          "27 15:07",
          "27 15:08",
          "27 15:09",
          "27 15:10",
          "27 15:11",
          "27 15:16",
          "27 15:17",
          "27 15:18",
          "27 15:19",
          "27 15:20",
          "27 15:23",
          "27 15:26",
          "27 15:27",
          "27 15:31",
          "27 15:33",
          "27 15:34",
          "27 15:38",
          "27 15:40",
          "27 15:41",
          "27 15:46",
          "27 15:48",
          "27 15:49",
          "27 15:50",
          "27 15:51",
          "27 15:52",
          "27 15:55",
          "27 16:00",
          "27 16:08",
          "27 16:14",
          "27 16:16",
          "27 16:18",
          "27 16:19",
          "27 16:22",
          "27 16:24",
          "27 16:26",
          "27 16:27",
          "27 16:29",
          "27 16:31",
          "27 16:32",
          "27 16:38",
          "27 16:45",
          "27 16:51",
          "27 16:52",
          "27 16:53",
          "27 16:55",
          "27 16:59",
          "27 17:02",
          "27 17:05",
          "27 17:11",
          "27 17:14",
          "27 17:17",
          "27 17:19",
          "27 17:24",
          "27 17:26",
          "27 17:31",
          "27 17:35",
          "27 17:37",
          "27 17:43",
          "27 17:44",
          "27 17:47",
          "27 17:53",
          "27 17:54",
          "27 17:59",
          "27 18:00",
          "27 18:02",
          "27 18:03",
          "27 18:08",
          "27 18:11",
          "27 18:13",
          "27 18:16",
          "27 18:17",
          "27 18:20",
          "27 18:23",
          "27 18:25",
          "27 18:26",
          "27 18:34",
          "27 18:42",
          "27 18:45",
          "27 18:46",
          "27 18:49",
          "27 18:51",
          "27 18:52",
          "27 18:54",
          "27 18:55",
          "27 18:58",
          "27 18:59",
          "27 19:00",
          "27 19:02",
          "27 19:06",
          "27 19:07",
          "27 19:08",
          "27 19:09",
          "27 19:10",
          "27 19:11",
          "27 19:12",
          "27 19:14",
          "27 19:18",
          "27 19:21",
          "27 19:23",
          "27 19:26",
          "27 19:27",
          "27 19:29",
          "27 19:30",
          "27 19:38",
          "27 19:39",
          "27 19:44",
          "27 19:45",
          "27 19:46",
          "27 19:47",
          "27 19:49",
          "27 19:57",
          "27 19:58",
          "27 20:01",
          "27 20:03",
          "27 20:06",
          "27 20:12",
          "27 20:14",
          "27 20:15",
          "27 20:17",
          "27 20:18",
          "27 20:23",
          "27 20:25",
          "27 20:26",
          "27 20:27",
          "27 20:28",
          "27 20:29",
          "27 20:31",
          "27 20:32",
          "27 20:34",
          "27 20:35",
          "27 20:36",
          "27 20:37",
          "27 20:39",
          "27 20:40",
          "27 20:41",
          "27 20:43",
          "27 20:45",
          "27 20:46",
          "27 20:48",
          "27 20:49",
          "27 20:54",
          "27 20:57",
          "27 20:59",
          "27 21:00"
         ],
         "y": [
          3.059999942779541,
          3.059999942779541,
          3.052000045776367,
          3.065000057220459,
          3.0741000175476074,
          3.0799999237060547,
          3.069999933242798,
          3.069999933242798,
          3.109999895095825,
          3.119999885559082,
          3.109299898147583,
          3.0999999046325684,
          3.0999999046325684,
          3.0999999046325684,
          3.1500000953674316,
          3.1500000953674316,
          3.1500000953674316,
          3.1700000762939453,
          3.190000057220459,
          3.2100000381469727,
          3.1700000762939453,
          3.2242000102996826,
          3.199899911880493,
          3.2300000190734863,
          3.2300000190734863,
          3.2053000926971436,
          3.1700000762939453,
          3.1600000858306885,
          3.1700000762939453,
          3.13700008392334,
          3.1700000762939453,
          3.1700000762939453,
          3.1549999713897705,
          3.1600000858306885,
          3.1700000762939453,
          3.1600000858306885,
          3.1700000762939453,
          3.160099983215332,
          3.1600000858306885,
          3.190999984741211,
          3.185800075531006,
          3.190000057220459,
          3.1700000762939453,
          3.186500072479248,
          3.200000047683716,
          3.190000057220459,
          3.190000057220459,
          3.1600000858306885,
          3.140000104904175,
          3.1110999584198,
          3.100100040435791,
          3.119999885559082,
          3.119999885559082,
          3.1500000953674316,
          3.1463000774383545,
          3.1487998962402344,
          3.1491000652313232,
          3.130000114440918,
          3.1245999336242676,
          3.1500000953674316,
          3.119999885559082,
          3.119999885559082,
          3.1386001110076904,
          3.119999885559082,
          3.119999885559082,
          3.140000104904175,
          3.134999990463257,
          3.130000114440918,
          3.1600000858306885,
          3.190000057220459,
          3.1600000858306885,
          3.1500000953674316,
          3.151099920272827,
          3.1500000953674316,
          3.1698999404907227,
          3.1700000762939453,
          3.1503000259399414,
          3.1600000858306885,
          3.180000066757202,
          3.1798999309539795,
          3.1700000762939453,
          3.1700000762939453,
          3.160900115966797,
          3.1500000953674316,
          3.1600000858306885,
          3.1700000762939453,
          3.1600000858306885,
          3.1649999618530273,
          3.1549999713897705,
          3.1500000953674316,
          3.177500009536743,
          3.1600000858306885,
          3.1549999713897705,
          3.1500000953674316,
          3.1600000858306885,
          3.1600000858306885,
          3.174999952316284,
          3.160099983215332,
          3.1700000762939453,
          3.174999952316284,
          3.200000047683716,
          3.2058000564575195,
          3.2011001110076904,
          3.2100000381469727,
          3.2200000286102295,
          3.240000009536743,
          3.243499994277954,
          3.25,
          3.244999885559082,
          3.25,
          3.2583000659942627,
          3.259000062942505,
          3.25,
          3.2528998851776123,
          3.259999990463257,
          3.2699999809265137,
          3.259999990463257,
          3.2799999713897705,
          3.240000009536743,
          3.255000114440918,
          3.255000114440918,
          3.255000114440918,
          3.255000114440918,
          3.255000114440918,
          3.2558000087738037,
          3.2799999713897705,
          3.2750000953674316,
          3.2750000953674316,
          3.2750000953674316,
          3.2750000953674316,
          3.2799999713897705,
          3.2249999046325684,
          3.2397000789642334,
          3.2100000381469727,
          3.2200000286102295,
          3.2298998832702637,
          3.2200000286102295,
          3.2200000286102295,
          3.2200000286102295,
          3.212100028991699,
          3.2200000286102295,
          3.2200000286102295,
          3.2200000286102295,
          3.2200000286102295,
          3.2200000286102295,
          3.240000009536743,
          3.2300000190734863,
          3.2286999225616455,
          3.2298998832702637,
          3.2200000286102295,
          3.2200000286102295,
          3.2079999446868896,
          3.2200000286102295,
          3.210099935531616,
          3.2111001014709473,
          3.2399001121520996,
          3.2298998832702637,
          3.2300000190734863,
          3.2200000286102295,
          3.200000047683716,
          3.2100000381469727,
          3.200000047683716,
          3.2200000286102295,
          3.2300000190734863,
          3.2100000381469727
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Close values for AADI (1 Day) , +4.90%"
        },
        "xaxis": {
         "nticks": 24,
         "showgrid": true,
         "title": {
          "text": "Hour"
         },
         "type": "category"
        },
        "yaxis": {
         "title": {
          "text": "Close value (in $)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_ticker_with_period(ticker, periode)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_data_by_period(ticker,periode):\n",
    "    dateToday=datetime.today()\n",
    "\n",
    "    if periode==\"1 Day\":\n",
    "        yesterday=dateToday-timedelta(days=1)\n",
    "        start_date=yesterday.replace(hour=0,minute=0,second=0,microsecond=0)\n",
    "    elif periode==\"1 Week\":\n",
    "        start_date=dateToday-timedelta(weeks=1)\n",
    "    elif periode==\"1 Month\":\n",
    "        start_date=dateToday-timedelta(weeks=4)\n",
    "    elif periode==\"6 Months\":\n",
    "        start_date=dateToday-timedelta(weeks=26)\n",
    "    elif periode==\"1 Year\":\n",
    "        start_date=dateToday-timedelta(weeks=52)\n",
    "    elif periode==\"5 Years\":\n",
    "        start_date=dateToday-timedelta(weeks=260)\n",
    "\n",
    "    if (periode==\"1 Day\") or (periode==\"1 Week\"):\n",
    "        filtered=df_min[(df_min[\"date\"]>=start_date)&(df_min[\"ticker\"]==ticker)]\n",
    "    else:\n",
    "        filtered=df_day[(df_day[\"date\"]>=start_date)&(df_day[\"ticker\"]==ticker)]\n",
    "    \n",
    "    filtered=filtered.sort_values(by=\"date\")\n",
    "    return filtered\n",
    "\n",
    "def plot_ticker_with_period(ticker,periode):\n",
    "    sub=filter_data_by_period(ticker,periode)\n",
    "\n",
    "    if not sub.empty:\n",
    "        firstClose=sub[\"close\"].iloc[0]\n",
    "        lastClose=sub[\"close\"].iloc[-1]\n",
    "        var=((lastClose-firstClose)/firstClose)*100\n",
    "    else:\n",
    "        var=0\n",
    "\n",
    "    if var>0:\n",
    "        varClose=f\"+{var:.2f}%\"\n",
    "    else:\n",
    "        varClose=f\"{var:.2f}%\"\n",
    "\n",
    "    if(periode==\"1 Day\"):\n",
    "        sub.loc[sub[\"date\"].diff()>timedelta(hours=12),\"close\"]=None\n",
    "        sub[\"heure\"]=sub[\"date\"].dt.strftime(\"%d %H:%M\")\n",
    "        sub=sub.sort_values(by=\"date\")\n",
    "        x_label=sub[\"heure\"]\n",
    "    elif(periode==\"1 Week\"):\n",
    "        sub.loc[sub[\"date\"].diff()>timedelta(hours=12),\"close\"]=None\n",
    "        sub=sub.sort_values(by=\"date\")\n",
    "        sub[\"day\"]=sub[\"date\"].dt.strftime(\"%d %H:%M\")\n",
    "        x_label=sub[\"day\"]\n",
    "    else:\n",
    "        sub=sub.sort_values(by=\"date\")\n",
    "        x_label=sub[\"date\"]\n",
    "    \n",
    "    fig=go.Figure()\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_label,\n",
    "        y=sub[\"close\"],\n",
    "        mode=\"lines\",\n",
    "        name=f\"Close value ({ticker})\",\n",
    "        line=dict(color=\"blue\",width=2),\n",
    "        connectgaps=False\n",
    "    ))\n",
    "    if(periode==\"1 Day\"):\n",
    "        titlex=\"Hour\"\n",
    "        ntickss=24\n",
    "    elif((periode==\"1 Week\")):\n",
    "        titlex=\"Date\"\n",
    "        ntickss=7\n",
    "    else:\n",
    "        titlex=\"Date\"\n",
    "\n",
    "    if((periode==\"1 Day\")or(periode==\"1 Week\")):\n",
    "        xaxiss=dict(title=titlex,type=\"category\",nticks=ntickss,showgrid=True)\n",
    "    else:\n",
    "        xaxiss=dict(title=titlex,showgrid=True)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Close values for {ticker} ({periode}) , {varClose}\",\n",
    "        xaxis=xaxiss,\n",
    "        yaxis_title=\"Close value (in $)\",\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "tickers=valid_nasdaq_list\n",
    "periode=[\"1 Day\",\"1 Week\",\"1 Month\",\"6 Months\",\"1 Year\",\"5 Years\"]\n",
    "\n",
    "interact(\n",
    "    plot_ticker_with_period,\n",
    "    ticker=widgets.Dropdown(options=tickers,description=\"Select Ticker: \"),\n",
    "    periode=widgets.Dropdown(options=periode,description=\"Select Period: \")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
